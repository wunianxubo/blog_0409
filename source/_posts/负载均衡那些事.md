---
title: 负载均衡那些事
date: 2018-06-25 16:55:00  
tags: [大型网站技术架构,分布式]    
categories: 分布式系统
toc: true
---
在网站的架构设计中，应用服务器应该被设计成无状态的，也就是说应用服务器不存储请求上下文信息。这样子的话，如果将部署相同应用的服务器组成一个集群，每次用户请求都可以发送到集群中任何一台服务器上进行请求处理，任何一台服务器的处理结果都是相同的。通过使用这种方式，让网站的可用性、伸缩性更好，能够处理更大的流量，这种方式称为"负载均衡"。在这篇文章中，我们一起来学习负载均衡，主要分下面三个部分来将，会依次介绍常用的负载均衡技术，常用的负载均衡算法以及这些负载均衡层在实际案例中的使用方式。  
<!-- more -->
### 一、常用负载均衡技术
#### 1. HTTP重定向负载均衡
这种方式利用HTTP重定向协议来实现负载均衡，如下图所示：  
![image](http://osrmzp0jr.bkt.clouddn.com/http.png)  
HTTP重定向服务器是一台普通的应用服务器，它唯一的功能就是根据用户的HTTP请求计算一台真实的Web服务器地址，并将该Web服务器的地址写入HTTP重定向响应（302状态吗）中返回给用户浏览器，之后浏览器自动重新请求该Web服务器地址。  

这种方式的负载均衡的优点是比较简单。缺点是：  
- 浏览器需要两次请求服务器才能完成一次访问，性能较差；
- 重定向服务器自身的处理能力可能会成为瓶颈，整个集群的伸缩性规模有限；
- 使用302响应吗重定向，有可能使搜索引擎判断为SEO作弊，降低搜索排名。

此种方式在实践中并不多见。  

#### 2. DNS域名解析负载均衡
这种方式利用DNS进行域名解析的同时进行负载均衡处理，如下图所示：  
![image](http://osrmzp0jr.bkt.clouddn.com/dns.png)  
在DNS服务器中配置多个A记录，每次域名解析请求都会根据负载均衡算法计算一个不同的IP地址返回，这样A记录中配置的多个服务器就构成集群，就可以实现负载均衡。  

这种方式的优点是：  
- 将负载均衡的工作转交给DNS，省掉了网站管理维护负载均衡服务器的麻烦，同时许多DNS还支持基于地理位置的域名解析，即会将域名解析成距离用户地理最近的一个服务器地址，这样可加快用户访问速度，改善性能。  

但是这种方式同样也存在一些缺点：  
- 目前的DNS解析是多级解析，每一级DNS都可能缓存A记录，当下线某台服务器时，A记录的修改生效具有滞后性；
- DNS负载均衡的控制权在域名服务商，网站无法对其做更多的改善和管理。

**实际上，网站会采用部分使用DNS域名解析的方式，利用域名解析作为第一级负载均衡手段，就是说域名解析得到的一组服务器并不是实际提供Web服务的物理处理器，而是同样提供负载均衡服务的内部服务器，这组内部负载均衡服务器再进行负载均衡，将请求发到真实的Web服务器。** 具体的形式可以看下面的案例。  

#### 3. 反向代理负载均衡（七层负载均衡）
利用反向代理服务器进行负载均衡。如下图所示：  
![image](http://osrmzp0jr.bkt.clouddn.com/nginxs.png)  

首先解释下正向代理和反向代理：  

**正向代理：**  
我想访问一个网站，但是这个网站我没有权限访问，但是我可以访问一个代理服务器，它可以访问我要访问的网站，于是我连上这个代理服务器，告诉代理服务器我要访问的地址，代理服务器取到结果后返回给我。   
也就是说，正向代理 是一个位于客户端和原始服务器(originserver)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端必须要进行一些特别的设置才能使用正向代理。  

**反向代理：**  
对于客户端而言它就像是原始服务器，并且客户端不需要进行任何特别的设置。客户端向反向代理的命名空间(name-space)中的内容发送普通请求，接着反向代理将判断向何处(原始服务器)转交请求，并将获得的内容返回给客户端，就像这些内容 原本就是它自己的一样。对用户来说，真正的原始服务器是透明的。

由于反向代理服务器转发请求在HTTP协议层面，因此也叫七层负载均衡（应用层负载均衡）。优点是和反向代理服务器功能集成在一起，部署简单。缺点是反向代理服务器是所有请求和响应的中转站，它的性能可能成为瓶颈。  

#### 4. IP负载均衡（四层负载均衡）
这种方式的原理是在网络层通过修改请求的目标地址来进行负载均衡。如下图所示：  
![image](http://osrmzp0jr.bkt.clouddn.com/iplb.png)  

这种方式中，真实服务器将响应数据包返回给负载均衡服务器有两种方式：  
1. 负载均衡服务器在修改目的IP地址的同时，将源地址修改为自身IP，即源地址转换（SNAT），这样Web服务器的相应会回到负载均衡服务器。  
2. 将负载均衡服务器同时作为真实物理器集群的网关服务器，这样所有响应的数据都会到达负载均衡服务器。  

IP负载均衡在内核进程完成数据分发，较反向代理负载均衡（在应用程序中分发数据）有更好的性能。但是由于所有请求的响应也都需要经过负载均衡服务器返回，集群中的最大响应数据吞吐量受限制于负载均衡服务器的网卡带宽的大小。  

#### 5. 数据链路层负载均衡（二层负载均衡）
这种方式，指的是在通信协议的数据链路层修改mac地址进行负载均衡。如下图所示：  
![image](http://osrmzp0jr.bkt.clouddn.com/maclb.png)  

**这种数据传输方式又称作三角传输模式，负载均衡数据分发的过程中不修改IP地址，只修改目的mac地址，通过配置真实物理服务器集群所有机器的虚拟IP和负载均衡服务器IP地址一致，达到了不用修改数据包的源地址和目的地址就可以进行数据分发的目的。由于实际处理请求的真实物理服务器IP和数据请求目的IP一致，所以不需要通过负载均衡服务器进行地址转换，可以将响应数据包直接返回给用户的浏览器，从而避免了负载均衡服务器网卡宽带成为瓶颈。这种负载均衡方式又称为直接路由方式（DR）**  

使用三角传输模式的链路层负载均衡是目前大型网站使用最广的一种负载均衡手段。其中有优秀的开源产品LVS（Linux Virtual Server），创始人是滴滴现任副总裁章文嵩。  

### 二、负载均衡算法  
负载均衡算法的作用是与服务器列表一起计算得到集群冲的一台Web服务器的地址，就是说给请求分配一个可处理的服务器。  
#### 1. 轮询
所有请求被依次分发到每台应用服务器上，即每台服务器需要处理的请求数目都相同，适合于所有服务器硬件都相同的场景。  

#### 2.加权轮询
根据应用服务器硬件性能的情况，在轮询的基础上，按照配置的权重将请求分发到每个服务器，性能好的服务器处理更多的请求。  

#### 3.随机
请求被随机分配到各个应用服务器，这种方式在很多场合下，简单易用。  

#### 4. 最少连接
记录每个服务器正在处理的连接数，将新到的请求分发到最少连接的服务器上。  

#### 5.源地址散列
根据请求来源的IP地址进行Hash计算，得到应用服务器，这样来自同一个ip地址的请求总是在同一个服务器上处理，该请求的上下文信息可以存到这台服务器上，在一个会话周期内重复使用，从而实现会话粘滞。  

### 三、负载均衡方案  
下面是以一个货运订单和物流管理的系统为例，看看各个阶段的负载均衡方案是怎样的，来看看实际案例中，我们应该怎么结合使用负载均衡。  

#### 第一阶段：独立的Nginx/HAProxy方案
在这个阶段，系统压力不大，但为了以后更好的扩展，我们将业务进行拆分，分成用户信息、订单信息、车辆信息三大模块。如下图所示：  

![image](http://osrmzp0jr.bkt.clouddn.com/nginx1.png)  

这时负载均衡层的作用是按照设定的访问规则，将不同系统的请求转发给对应的系统。  

#### 第二阶段：Nginx/HAProxy + KeepAlived方案
这个阶段，系统的访问压力进一步加大，我们在单节点处还能满足业务要求的情况下，为负载层引入热备方案，以此来保证在节点崩溃时，另一个节点可以接替其工作，提高系统的可用性。  

![image](http://osrmzp0jr.bkt.clouddn.com/nginx2.png)  

#### 第三阶段：LVS(DR) + Nginx + KeepAlived方案
在这个阶段，为了追求更大的吞吐量和更大的请求流量，我们加入LVS技术。LVS技术负载第一层负载，然后再将访问请求转发到后台若干台Nginx上。在收到请求并处理完成后，Nginx将直接发送结果到请求方，不会再经LVS回发。  

![image](http://osrmzp0jr.bkt.clouddn.com/nginx3.png)  

加入LVS后，Nginx就不再需要使用热备方案。因为首先Nginx不再是一个单个节点进行负载处理，而是作为一个集群，可用性提升；另外LVS对于后端的服务器自带基于端口的健康检查功能。  

这样子LVS就变成了是单节点处理的，虽然LVS十分稳定，但是为了保证高可用性和高稳定性，我们还是为LVS做一个热备节点，以备不时之需。  

#### 第四阶段：DNS轮询 + LVS(DR) + Nginx + KeepAlived方案  

![image](http://osrmzp0jr.bkt.clouddn.com/nginx4.png)  

为了满足更高的并发需求，更大的访问量，在对业务进行外网暴露的基础上，我们在最前端做了一个DNS轮询，然后将对用户信息系统的访问压力首先分摊到两个对称LVS组上面，再由LVS继续向下分拆访问压力。  

注意到，这里的负载均衡方案和上面不同：  
- 首先不向前面方案中，使用目录名来分割业务系统了，而是直接将业务系统的访问使用不同的二级域名进行拆分。这样子有利于每个业务系统都拥有自己独立的负载均衡层。在这只是用户信息子系统的负载均衡层，订单子系统、物流子系统也会有相应的负载均衡层。
- 理论上，在LVS下方的Nginx服务可以实现无限制的扩展，Nginx本身也不需要KeepAlived保持热备，而是全部交给上层的LVS进行健康状态检查。  

可以看到，没有独立的LVS方案，这是由于LVS为了保证其高性能对可配置性有所牺牲，单独使用的话往往无法满足业务层对负载层灵活分配请求的要求。  

### 小结
本篇文章主要先介绍了常用的负载均衡的技术，以及常用的负载均衡的方法。在实际的网站系统架构中，会将多种负载均衡技术结合在一起，从而使系统具有更好的性能，更好的可用性。所以我们在第三部分以一个货运订单物流管理系统为例，分析了在实际案例中负载均衡技术的使用。当然，这些都是停留在理论阶段，在具体实施过程中，可能会遇到具体的负载均衡服务器的配置问题，负载均衡算法的选择问题，或是其他各种各样的问题，我还没有深入接触过这样的大型系统，希望在以后工作学习中进行更深的学习。  

参考文章：  
1. 《大型网站技术架构原理》 李智慧  
2. 架构设计：负载均衡层设计方案（1）——负载场景和解决方式 https://blog.csdn.net/yinwenjie/article/details/46605451